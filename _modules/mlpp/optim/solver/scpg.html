<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>mlpp.optim.solver.scpg &#8212; MLPP 0.1 documentation</title>
    
    <link rel="stylesheet" href="../../../../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="top" title="MLPP 0.1 documentation" href="../../../../index.html" />
    <link rel="up" title="Module code" href="../../../index.html" /> 
  </head>
  <body role="document">
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../../../../index.html">MLPP 0.1 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for mlpp.optim.solver.scpg</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf8 -*-</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">norm</span>

<span class="kn">from</span> <span class="nn">mlpp.optim.solver.base</span> <span class="k">import</span> <span class="n">SolverFirstOrder</span>
<span class="kn">from</span> <span class="nn">mlpp.optim.prox.base</span> <span class="k">import</span> <span class="n">Prox</span>
<span class="kn">from</span> <span class="nn">mlpp.optim.model.base</span> <span class="k">import</span> <span class="n">ModelSecondOrder</span><span class="p">,</span> <span class="n">ModelSelfConcordant</span>
<span class="kn">from</span> <span class="nn">mlpp.optim.utils</span> <span class="k">import</span> <span class="n">relative_distance</span>

<span class="n">__author__</span> <span class="o">=</span> <span class="s1">&#39;MartinBompaire&#39;</span>


<div class="viewcode-block" id="SCPG"><a class="viewcode-back" href="../../../../optim/solver/scpg.html#mlpp.optim.solver.SCPG">[docs]</a><span class="k">class</span> <span class="nc">SCPG</span><span class="p">(</span><span class="n">SolverFirstOrder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Minimize the objective</span>

<span class="sd">    .. math:: f(x) + g(x)</span>

<span class="sd">    using the Proximal Gradient algorithm</span>
<span class="sd">    This algorithm assumes that f and g are both convex, that</span>
<span class="sd">    f is standard self-concordant and that g is prox-capable.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    modified : `bool` (default False)</span>
<span class="sd">        Weather or not using the modified version fo the algorithm.</span>

<span class="sd">    step : `float` default=None</span>
<span class="sd">        Step-size of the algorithm. If ``linesearch=True``, this is the</span>
<span class="sd">        first step-size to be used in the linesearch</span>
<span class="sd">        (typically taken too large). Otherwise, it&#39;s the constant step</span>
<span class="sd">        to be used along iterations.</span>

<span class="sd">    tol : `float`, default=0.</span>
<span class="sd">        The tolerance of the solver (iterations stop when the stopping</span>
<span class="sd">        criterion is below it). By default the solver does ``max_iter``</span>
<span class="sd">        iterations</span>

<span class="sd">    max_iter : `int`, default=100</span>
<span class="sd">        Maximum number of iterations of the solver</span>

<span class="sd">    linesearch_step_increase : `float`, default=2.</span>
<span class="sd">        Factor of step increase when using linesearch</span>

<span class="sd">    linesearch_step_decrease : `float`, default=0.5</span>
<span class="sd">        Factor of step decrease when using linesearch</span>

<span class="sd">    verbose : `bool`, default=True</span>
<span class="sd">        If `True`, we verbose things, otherwise the solver does not</span>
<span class="sd">        print anything (but records information in history anyway)</span>

<span class="sd">    print_every : `int`, default=10</span>
<span class="sd">        Print history information when ``n_iter`` (iteration number) is</span>
<span class="sd">        a multiple of ``print_every``</span>

<span class="sd">    record_every : `int`, default=1</span>
<span class="sd">        Record history information when ``n_iter`` (iteration number) is</span>
<span class="sd">        a multiple of ``record_every``</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    model : `Model`</span>
<span class="sd">        The model to solve</span>

<span class="sd">    prox : `Prox`</span>
<span class="sd">        Proximal operator to solve</span>

<span class="sd">    time_start : `str`</span>
<span class="sd">        Start date of the call to ``solve()``</span>

<span class="sd">    time_elapsed : `float`</span>
<span class="sd">        Duration of the call to ``solve()``, in seconds</span>

<span class="sd">    time_end : `str`</span>
<span class="sd">        End date of the call to ``solve()``</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_attrinfos</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model_ssc&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;writable&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
        <span class="s1">&#39;prox_ssc&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;writable&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
        <span class="s1">&#39;_th_gain&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;_initial_n_hessiannorm_calls&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;writable&quot;</span><span class="p">:</span> <span class="kc">False</span>
        <span class="p">},</span>
    <span class="p">}</span>

    <span class="k">class</span> <span class="nc">_ModelStandardSC</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The standard self concordant version of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelSecondOrder</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_sc_constant</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr_sqrt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_n_hessiannorm_calls</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

        <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">out</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">loss_and_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">out</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>
            <span class="k">return</span> <span class="n">loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span><span class="p">,</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">hessian_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">point</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">hessian_norm</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">point</span><span class="p">)</span> <span class="o">*</span> \
                   <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr_sqrt</span>

        <span class="k">def</span> <span class="nf">original_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Returns the loss of the original model form the loss of the</span>
<span class="sd">            standard self-concordant model</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="n">loss_ssc</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

        <span class="k">def</span> <span class="nf">original_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj_ssc</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Returns the loss of the original model form the loss of the</span>
<span class="sd">            standard self-concordant model</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="n">obj_ssc</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

    <span class="k">class</span> <span class="nc">_ProxStandardSC</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The standard self concordant version of the prox according to the</span>
<span class="sd">        model</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span> <span class="nf">set_original_prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prox</span><span class="p">:</span> <span class="n">Prox</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span> <span class="o">=</span> <span class="n">prox</span>

        <span class="k">def</span> <span class="nf">set_self_conc_constant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">self_conc_constant</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="n">self_conc_constant</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span>

        <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                 <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span><span class="p">,</span>
                                          <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">linesearch_step_increase</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.</span><span class="p">,</span>
                 <span class="n">linesearch_step_decrease</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">print_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">record_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">modified</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                                  <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="n">print_every</span><span class="p">,</span>
                                  <span class="n">record_every</span><span class="o">=</span><span class="n">record_every</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_increase</span> <span class="o">=</span> <span class="n">linesearch_step_increase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_decrease</span> <span class="o">=</span> <span class="n">linesearch_step_decrease</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modified</span> <span class="o">=</span> <span class="n">modified</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ProxStandardSC</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span> <span class="o">=</span> <span class="mi">0</span>

<div class="viewcode-block" id="SCPG.set_model"><a class="viewcode-back" href="../../../../optim/solver/scpg.html#mlpp.optim.solver.SCPG.set_model">[docs]</a>    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelSecondOrder</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set model in the solver</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : `ModelSecondOrder` and `ModelSelfConcordant`</span>
<span class="sd">            Sets the model in the solver. The model gives</span>
<span class="sd">            information about the model (loss, gradient, among</span>
<span class="sd">            other things)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : `Solver`</span>
<span class="sd">            The same instance with given model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;model_ssc&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ModelStandardSC</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">set_self_conc_constant</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_sc_constant</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SCPG.set_prox"><a class="viewcode-back" href="../../../../optim/solver/scpg.html#mlpp.optim.solver.SCPG.set_prox">[docs]</a>    <span class="k">def</span> <span class="nf">set_prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prox</span><span class="p">:</span> <span class="n">Prox</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set proximal operator in the solver.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prox : `Prox`</span>
<span class="sd">            The proximal operator of the penalization function</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : `Solver`</span>
<span class="sd">            The solver with given prox</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;prox&#39;</span><span class="p">,</span> <span class="n">prox</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">set_original_prox</span><span class="p">(</span><span class="n">prox</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_objective_ssc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute objective at x for the standard self concordant model</span>

<span class="sd">        .. math::`\frac{M_f^2}{4} * (f(x) + g(x))`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : `float`</span>
<span class="sd">            The value at which we compute the objective</span>

<span class="sd">        loss_ssc: `float`</span>
<span class="sd">            The value of the f(x) if it is already known</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">loss_ssc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">loss_ssc</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span> <span class="o">=</span> \
            <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="n">_initialize_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span>
                                                <span class="n">n_empty_vectors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">grad_x_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span>

    <span class="k">def</span> <span class="nf">_perform_line_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">step</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_increase</span>
        <span class="n">llh_y_ssc</span><span class="p">,</span> <span class="n">grad_y_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">obj_y_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_y_ssc</span><span class="p">)</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>

            <span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">step</span> <span class="o">*</span> <span class="n">grad_y_ssc</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">test</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obj_x_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">envelope</span> <span class="o">=</span> <span class="n">obj_y_ssc</span> <span class="o">+</span> \
                           <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grad_y_ssc</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> \
                           <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">step</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
                <span class="n">test</span> <span class="o">=</span> <span class="p">(</span><span class="n">obj_x_ssc</span> <span class="o">&lt;=</span> <span class="n">envelope</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">step</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_decrease</span>
        <span class="k">return</span> <span class="n">step</span>

    <span class="k">def</span> <span class="nf">_gradient_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">grad_x_ssc</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span>
                       <span class="n">n_iter</span><span class="p">,</span> <span class="n">l_k</span><span class="p">):</span>
        <span class="c1"># Testing if our value of l_k fits the condition for the stepsize</span>
        <span class="c1"># alpha_k</span>

        <span class="c1"># Barzilai-Borwein step</span>
        <span class="k">if</span> <span class="n">n_iter</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">prev_x</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">l_k</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_x_ssc</span> <span class="o">-</span> <span class="n">prev_grad_x_ssc</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">/</span> \
                      <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">l_k</span> <span class="o">*=</span> <span class="mi">2</span>

        <span class="n">prev_grad_x_ssc</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">grad_x_ssc</span>
        <span class="n">prev_x</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="c1"># Compute x_new, next step vector</span>
        <span class="n">condition</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">condition</span><span class="p">:</span>
            <span class="n">y_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">grad_x_ssc</span> <span class="o">/</span> <span class="n">l_k</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">l_k</span><span class="p">)</span>
            <span class="n">d_k</span> <span class="o">=</span> <span class="n">y_k</span> <span class="o">-</span> <span class="n">x</span>
            <span class="n">beta_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">l_k</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">d_k</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">lambda_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">hessian_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d_k</span><span class="p">))</span>

            <span class="n">alpha_k</span> <span class="o">=</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span> <span class="o">/</span> \
                      <span class="p">(</span><span class="n">lambda_k</span> <span class="o">*</span> <span class="p">(</span><span class="n">lambda_k</span> <span class="o">+</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span><span class="p">))</span>
            <span class="c1"># condition = lambda_k &gt;= 1 or lambda_k &gt;= beta_k</span>
            <span class="n">condition</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">alpha_k</span> <span class="o">&lt;</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">condition</span><span class="p">:</span>
                <span class="n">l_k</span> <span class="o">/=</span> <span class="mi">2</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">l_k</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;l_k is nan&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span> <span class="o">=</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span> <span class="o">/</span> <span class="n">lambda_k</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span>
                                                            <span class="o">/</span> <span class="n">lambda_k</span><span class="p">)</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha_k</span> <span class="o">*</span> <span class="n">d_k</span>

        <span class="c1"># we also &quot;return&quot; grad_x_ssc and prev_grad_x_ssc which are filled</span>
        <span class="c1"># during function&#39;s run</span>
        <span class="k">return</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_k</span><span class="p">,</span> <span class="n">alpha_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="p">,</span> <span class="n">lambda_k</span><span class="p">,</span> <span class="n">l_k</span>

    <span class="k">def</span> <span class="nf">_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="n">e5</span><span class="p">):</span>

        <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_values</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified</span><span class="p">:</span>
            <span class="n">grad_y_ssc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="n">e5</span>

        <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_perform_line_search</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>
        <span class="n">l_k</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">step</span>

        <span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

            <span class="n">prev_obj</span> <span class="o">=</span> <span class="n">obj</span>

            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="p">,</span> <span class="n">lambda_k</span><span class="p">,</span> <span class="n">l_k</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">grad_x_ssc</span><span class="p">,</span>
                                    <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">l_k</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified</span><span class="p">:</span>
                <span class="n">llh_y_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_y_ssc</span><span class="p">)</span>
                <span class="n">llh_x_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_y_ssc</span><span class="p">)</span> <span class="o">&lt;</span> \
                        <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_x_ssc</span><span class="p">):</span>
                    <span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">y</span>
                    <span class="n">grad_x_ssc</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">grad_y_ssc</span>
                    <span class="n">llh_x_ssc</span> <span class="o">=</span> <span class="n">llh_y_ssc</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">llh_x_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>

            <span class="n">rel_delta</span> <span class="o">=</span> <span class="n">relative_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">)</span>
            <span class="n">llh_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">original_loss</span><span class="p">(</span><span class="n">llh_x_ssc</span><span class="p">)</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">llh_x</span><span class="p">)</span>
            <span class="n">rel_obj</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="n">prev_obj</span><span class="p">)</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">prev_obj</span><span class="p">)</span>
            <span class="n">obj_gain</span> <span class="o">=</span> <span class="n">prev_obj</span> <span class="o">-</span> <span class="n">obj</span>

            <span class="n">converged</span> <span class="o">=</span> <span class="n">rel_obj</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span>
            <span class="c1"># if converged, we stop the loop and record the last step in history</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_history</span><span class="p">(</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">converged</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                                 <span class="n">rel_delta</span><span class="o">=</span><span class="n">rel_delta</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">alpha_k</span><span class="p">,</span>
                                 <span class="n">rel_obj</span><span class="o">=</span><span class="n">rel_obj</span><span class="p">,</span> <span class="n">l_k</span><span class="o">=</span><span class="n">l_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="o">=</span><span class="n">beta_k</span><span class="p">,</span>
                                 <span class="n">lambda_k</span><span class="o">=</span><span class="n">lambda_k</span><span class="p">,</span> <span class="n">th_gain</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span><span class="p">,</span>
                                 <span class="n">obj_gain</span><span class="o">=</span><span class="n">obj_gain</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">converged</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s2">&quot;solution&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">_handle_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the history of the solver.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;_initial_n_hessiannorm_calls&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">n_calls_hessian_norm</span><span class="p">)</span>

        <span class="n">hessiannorm_calls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">n_calls_hessian_norm</span> <span class="o">-</span> \
                            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_n_hessiannorm_calls</span>
        <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="n">_handle_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span><span class="p">,</span>
                                         <span class="n">n_calls_hessiannorm</span><span class="o">=</span><span class="n">hessiannorm_calls</span><span class="p">,</span>
                                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/simulation/poisson_process_simulation.html">Poisson processes simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/simulation/hawkes_simulation.html">Hawkes processes simulation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/inference/hawkes_non_parametric.html">Hawkes non parametric inference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/optimization/stochastic_solver.html">Stochastic solvers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/optimization/linear_model.html">Generalized linear models</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../z_tutorials/misc/time_function.html">Time functions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/optimization_toolbox.html">Presentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/model.html">Models [<code class="docutils literal"><span class="pre">mlpp.optim.model</span></code>]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/prox.html">Proximal operators [<code class="docutils literal"><span class="pre">mlpp.optim.prox</span></code>]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim/solver.html">Solvers [<code class="docutils literal"><span class="pre">mlpp.optim.solver</span></code>]</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../simu/simu.html">Simulation toolbox [<code class="docutils literal"><span class="pre">mlpp.simulation</span></code>]</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../dev/dev.html">Developer documentation</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../../../../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
            </form>
          </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="../../../../py-modindex.html" title="Python Module Index"
              >modules</a> |
            <a href="../../../../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2015, Emmanuel Bacry, Martin Bompaire, Stephane Gaiffas, Maryan Morel, Sren Poulsen.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.8.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>